version: '3'

networks:
  schedule_generator:
    driver: bridge
    ipam:
      config:
        - subnet: 192.168.5.0/24
          gateway: 192.168.5.1

services:
  mongodb:
    image: mongo:latest
    ports:
      - 27017:27017
    networks:
      schedule_generator:
        ipv4_address: 192.168.5.4
    volumes:
      - mongo_data:/data/db
    restart: on-failure

  frontfacingserver_webapp:
    build:  .
    ports: 
      - 443:443
      - 80:443
      - 5000:5000
      - 4200:4200
    command: >
     bash -c "systemctl start nginx &&
      cd /ffs && /venv/bin/python app.py &
      cd /fe && npm start"
    networks:
      schedule_generator:
        ipv4_address: 192.168.5.2
    depends_on:
      - mongodb
    volumes:
      - dataset:/app/dataset
    restart: on-failure
  
  worker1:
    build: ./cpp-invoker/.
    networks:
      schedule_generator:
        ipv4_address: 192.168.5.6
    ports:
      - 5000
    command: >
      bash -c "cd /invoker && /venv/bin/python app.py 192.168.5.6:5000"
    restart: on-failure

  worker2:
    build: ./cpp-invoker/.
    networks:
      schedule_generator:
        ipv4_address: 192.168.5.7
    ports:
      - 5000
    command: >
      bash -c "cd /invoker && /venv/bin/python app.py 192.168.5.7:5000"
    restart: on-failure
    
  worker3:
    build: ./cpp-invoker/.
    networks:
      schedule_generator:
        ipv4_address: 192.168.5.8
    ports:
      - 5000
    command: >
      bash -c "cd /invoker && /venv/bin/python app.py 192.168.5.8:5000"
    restart: on-failure

  haproxy:
    image: haproxy
    networks:
      schedule_generator:
        ipv4_address: 192.168.5.5
    restart: on-failure
    depends_on:
      - worker1
      - worker2
      - worker3
    ports:
      - 80
    volumes:
      - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg
  
volumes:
  dataset:
  mongo_data: